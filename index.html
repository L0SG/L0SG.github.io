<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sang-gil Lee</title>

  <meta name="author" content="Sang-gil Lee">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
        href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
<table
  style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
  <tr style="padding:0px">
    <td style="padding:0px">
      <table
        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr style="padding:0px">
          <td style="padding:2.5%;width:63%;vertical-align:middle">
            <p style="text-align:center">
              <name>Sang-gil Lee</name>
            </p>
            <p>I am a final-year Ph.D. candidate at Data Science & AI Lab. (DSAIL) from Seoul National University,
              South Korea. I do deep generative models for sequence.
            </p>
            <p>
              I was a research intern at <a href="https://www.nvidia.com/">NVIDIA</a>, advised by <a
              href="https://wpingnet.github.io/">Wei Ping</a> and <a
              href="https://scholar.google.com/citations?user=7BRYaGcAAAAJ">Boris Ginsburg</a>.
              Prior to that, I did internships at <a
              href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft
              Research Asia</a>, advised by <a href="https://tan-xu.github.io/">Xu Tan</a>, <a
              href="https://www.microsoft.com/en-us/research/people/taoqin/">Tao Qin</a> (speech), and
              <a href="https://www.binshao.info/">Bin Shao</a> (bioinformatics).
              I received my B.S. in Electrical and Computer Engineering from <a
              href="https://en.snu.ac.kr">Seoul National University</a>.
              <br>
              <br>
              I am open to job opportunities at spring 2023. It'd be happy to have a chat!

            </p>
            <p style="text-align:center">
              <a href="mailto:tkdrlf9202@gmail.com">Email</a> &nbsp/&nbsp
              <a href="data/Sang-gil-Lee-CV.pdf">CV</a> &nbsp/&nbsp
              <a href="https://www.linkedin.com/in/sang-gil-lee/">LinkedIn</a> &nbsp/&nbsp
              <a href="https://scholar.google.com/citations?user=P93s2UQAAAAJ&hl=en">Google Scholar</a>
              &nbsp/&nbsp
              <a href="https://twitter.com/L0SG">Twitter</a> &nbsp/&nbsp
              <a href="https://github.com/L0SG/">Github</a>
            </p>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">

            <div class="item">
              <div class="item2">
                <img src='images/L0SG.png'></div>
              <img src='images/Sang-gil-Lee.png'>
            </div>

          </td>

        </tbody>
      </table>
      <table
        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Research</heading>
            <p>
              My research interest spans a wide range of deep generative models (AR, flow, GAN, diffusion,
              etc.) applied to sequential data.
              Specifically, I focus on time-domain waveform data (speech / audio) to push the boundaries
              of generative modeling for audio.
              I am also broadly interested in speech / audio applications, including text-to-speech, voice
              conversion, and music generation.
              Representative papers are <span class="highlight">highlighted</span>.
            </p>
          </td>
        </tr>
        </tbody>
      </table>
      <table
        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>

        <tr onmouseout="bigvgan_stop()" onmouseover="bigvgan_start()" bgcolor="#ffffd0">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/bigvgan.png' width="160">
            </div>
            <script type="text/javascript">
                function bigvgan_start() {
                    document.getElementById('bigvgan_image').style.opacity = "1";
                }

                function bigvgan_stop() {
                    document.getElementById('bigvgan_image').style.opacity = "0";
                }

                bigvgan_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2206.04658">
              <papertitle>BigVGAN: A Universal Neural Vocoder with Large-Scale Training</papertitle>
            </a>
            <br>
            <strong>Sang-gil Lee</strong>,
            <a href="https://wpingnet.github.io/">Wei Ping</a>,
            <a href="https://scholar.google.com/citations?user=7BRYaGcAAAAJ">Boris Ginsburg</a>,
            <a href="https://ctnzr.io/">Bryan Catanzaro</a>,
            <a href="https://scholar.google.com/citations?user=Bphl_fIAAAAJ">Sungroh Yoon</a>
            <br>
            <em>arXiv preprint</em>, 2022
            <br> <a href="https://nv-adlr.github.io/projects/bigvgan/">project page</a> /
            <a href="https://arxiv.org/abs/2206.04658">arXiv</a> /
            <a href="https://github.com/NVIDIA/BigVGAN">code</a> /
            <a href="https://bigvgan-demo.github.io/">demo</a>
            <p></p>
            <p>BigVGAN is a universal audio synthesizer that achieves unprecedented zero-shot performance on various
              unseen
              environments using anti-aliased periodic nonlinearity and large-scale training. </p>
          </td>
        </tr>

        <tr onmouseout="priorgrad_stop()" onmouseover="priorgrad_start()" bgcolor="#ffffd0">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/priorgrad.png' width="160">
            </div>
            <script type="text/javascript">
                function priorgrad_start() {
                    document.getElementById('priorgrad_image').style.opacity = "1";
                }

                function priorgrad_stop() {
                    document.getElementById('priorgrad_image').style.opacity = "0";
                }

                priorgrad_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://openreview.net/pdf?id=_BNiN4IjC5">
              <papertitle>PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Dependent Adaptive
                Prior
              </papertitle>
            </a>
            <br>
            <strong>Sang-gil Lee</strong>,
            <a href="https://scholar.google.com/citations?user=4ojbJpoAAAAJ">Heeseung Kim</a>,
            <a href="https://scholar.google.com/citations?user=M8RX0MEAAAAJ">Chaehun Shin</a>,
            <a href="https://tan-xu.github.io/">Xu Tan</a>,
            <a href="https://changliu00.github.io/">Chang Liu</a>,
            <a href="https://www.microsoft.com/en-us/research/people/meq/">Qi Meng</a>,
            <a href="https://www.microsoft.com/en-us/research/people/taoqin/">Tao Qin</a>,
            <a href="https://weichen-cas.github.io/">Wei Chen</a>,
            <a href="https://scholar.google.com/citations?user=Bphl_fIAAAAJ">Sungroh Yoon</a>,
            <a href="https://www.microsoft.com/en-us/research/people/tyliu/">Tie-Yan Liu</a>
            <br>
            <em>International Conference on Learning Representations (ICLR)</em>, 2022
            <br> <a href="https://speechresearch.github.io/priorgrad/">project page</a> /
            <a href="https://arxiv.org/abs/2106.06406">arXiv</a> /
            <a href="https://github.com/microsoft/NeuralSpeech">code</a> /
            <a href="https://iclr.cc/virtual/2022/poster/6445">poster</a>
            <p></p>
            <p>PriorGrad presents an efficient method for constructing a data-dependent non-standard Gaussian prior for
              training and sampling from diffusion models applied to speech synthesis. </p>
          </td>
        </tr>

        <tr onmouseout="nanoflow_stop()" onmouseover="nanoflow_start()" bgcolor="#ffffd0">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/nanoflow.png' width="160">
            </div>
            <script type="text/javascript">
                function nanoflow_start() {
                    document.getElementById('nanoflow_image').style.opacity = "1";
                }

                function nanoflow_stop() {
                    document.getElementById('nanoflow_image').style.opacity = "0";
                }

                nanoflow_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://proceedings.neurips.cc/paper/2020/file/a1c3ae6c49a89d92aef2d423dadb477f-Paper.pdf">
              <papertitle>NanoFlow: Scalable Normalizing Flows with Sublinear Parameter Complexity</papertitle>
            </a>
            <br>
            <strong>Sang-gil Lee</strong>,
            <a href="https://scholar.google.com/citations?user=6qGppvkAAAAJ">Sungwon Kim</a>,
            <a href="https://scholar.google.com/citations?user=Bphl_fIAAAAJ">Sungroh Yoon</a>
            <br>
            <em>Neural Information Processing Systems (NeurIPS)</em>, 2020
            <br>
            <a href="https://arxiv.org/abs/2006.06280">arXiv</a> /
            <a href="https://github.com/L0SG/NanoFlow">code</a> /
            <a href="https://nips.cc/virtual/2020/poster/17696">poster</a>
            <p></p>
            <p>NanoFlow uses a single neural network for multiple transformation stages in normalizing flows, which
              provides an efficient compression for flow-based generative models.</p>
          </td>
        </tr>

        <tr onmouseout="flowavenet_stop()" onmouseover="flowavenet_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/flowavenet.png' width="160">
            </div>
            <script type="text/javascript">
                function flowavenet_start() {
                    document.getElementById('flowavenet_image').style.opacity = "1";
                }

                function flowavenet_stop() {
                    document.getElementById('flowavenet_image').style.opacity = "0";
                }

                flowavenet_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="http://proceedings.mlr.press/v97/kim19b/kim19b.pdf">
              <papertitle>FloWaveNet: A Generative Flow for Raw Audio</papertitle>
            </a>
            <br>
            <a href="https://scholar.google.com/citations?user=6qGppvkAAAAJ">Sungwon Kim</a>,
            <strong>Sang-gil Lee</strong>,
            <a href="https://scholar.google.com/citations?user=AcVToQUAAAAJ">Jongyoon Song</a>,
            <a href="https://jaywalnut310.github.io/">Jaehyeon Kim</a>,
            <a href="https://scholar.google.com/citations?user=Bphl_fIAAAAJ">Sungroh Yoon</a>
            <br>
            <em>International Conference on Machine Learning (ICML)</em>, 2019
            <br>
            <a href="https://arxiv.org/abs/1811.02155">arXiv</a> /
            <a href="https://github.com/ksw0306/FloWaveNet">code</a> /
            <a href="https://ksw0306.github.io/flowavenet-demo">demo</a> /
            <a href="https://pdfs.semanticscholar.org/9e79/377defb3385ae4dfb5e345c85686e27ca7a5.pdf">poster</a>
            <p></p>
            <p>One of the first flow-based generative models for a fast and parallel synthesis of audio waveform, which
              enables a likelihood-based neural vocoder without any auxiliary loss.</p>
          </td>
        </tr>

        <tr onmouseout="ttsql_stop()" onmouseover="ttsql_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/ttsql.png' width="160">
            </div>
            <script type="text/javascript">
                function ttsql_start() {
                    document.getElementById('ttsql_image').style.opacity = "1";
                }

                function ttsql_stop() {
                    document.getElementById('ttsql_image').style.opacity = "0";
                }

                ttsql_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/1905.11499">
              <papertitle>One-Shot Learning for Text-to-SQL Generation</papertitle>
            </a>
            <br>
            <a href="https://scholar.google.com/citations?user=5Psi6aYAAAAJ">Dongjun Lee</a>,
            <a href="https://www.jaesikyoon.com/">Jaesik Yoon</a>,
            <a href="https://scholar.google.com/citations?user=AcVToQUAAAAJ">Jongyoon Song</a>,
            <strong>Sang-gil Lee</strong>,
            <a href="https://scholar.google.com/citations?user=Bphl_fIAAAAJ">Sungroh Yoon</a>
            <br>
            <em>arXiv preprint</em>, 2019
            <br>
            <a href="https://arxiv.org/abs/1905.11499">arXiv</a>
            <p></p>
            <p>Template-based one-shot text-to-SQL generative model based on a Candidate Search Network & Pointer
              Network.</p>
          </td>
        </tr>

        <tr onmouseout="seqgan_stop()" onmouseover="seqgan_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/seqgan.png' width="160">
            </div>
            <script type="text/javascript">
                function seqgan_start() {
                    document.getElementById('seqgan_image').style.opacity = "1";
                }

                function seqgan_stop() {
                    document.getElementById('seqgan_image').style.opacity = "0";
                }

                seqgan_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/1710.11418">
              <papertitle>Polyphonic Music Generation with Sequence Generative Adversarial Networks
              </papertitle>
            </a>
            <br>
            <strong>Sang-gil Lee</strong>,
            <a href="https://sites.google.com/view/uiwon-hwang">Uiwon Hwang</a>,
            <a href="https://scholar.google.co.kr/citations?user=dWKk68wAAAAJ">Seonwoo Min</a>,
            <a href="https://scholar.google.com/citations?user=Bphl_fIAAAAJ">Sungroh Yoon</a>
            <br>
            <em>arXiv preprint</em>, 2017
            <br>
            <a href="https://arxiv.org/abs/1710.11418">arXiv</a> /
            <a href="https://github.com/L0SG/seqgan-music">code</a>
            <p></p>
            <p>Investigates an efficient musical word representation from polyphonic MIDI data for SeqGAN, which
              simultaneously captures chords and melodies with dynamic timings.</p>
          </td>
        </tr>

        <tr onmouseout="snn_stop()" onmouseover="snn_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/snn.png' width="160">
            </div>
            <script type="text/javascript">
                function snn_start() {
                    document.getElementById('snn_image').style.opacity = "1";
                }

                function snn_stop() {
                    document.getElementById('snn_image').style.opacity = "0";
                }

                snn_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/1611.02416">
              <papertitle>An Efficient Approach to Boosting Performance of Deep Spiking Network Training
              </papertitle>
            </a>
            <br>
            Seongsik Park,
            <strong>Sang-gil Lee</strong>,
            Hyunha Nam,
            <a href="https://scholar.google.com/citations?user=Bphl_fIAAAAJ">Sungroh Yoon</a>
            <br>
            <em>Neural Information Processing Systems (NIPS) Workshop on Computing with Spikes</em>, 2016
            <br>
            <a href="https://arxiv.org/abs/1611.02416">arXiv</a>
            <p></p>
            <p>Investigates various initialization and backward control schemes of the membrane potential for training
              deep spiking networks.</p>
          </td>
        </tr>


        </tbody>
      </table>


      <table
        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Projects</heading>
            <p>
              During my stay at DSAIL, I collaborated with <a href="http://www.snuh.org/global/en/main.do">Seoul
              National University Hospital</a> on a computer aided diagnosis of liver cancer.
              The project has yielded a high-performance medical object detection model to help reduce human errors from
              radiologists for the early detection of liver disease.
            </p>
          </td>
        </tr>
        </tbody>
      </table>
      <table
        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>

        <tr onmouseout="gssdpp_stop()" onmouseover="gssdpp_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/gssdpp.png' width="160">
            </div>
            <script type="text/javascript">
                function gssdpp_start() {
                    document.getElementById('gssdpp_image').style.opacity = "1";
                }

                function gssdpp_stop() {
                    document.getElementById('gssdpp_image').style.opacity = "0";
                }

                gssdpp_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://ieeexplore.ieee.org/abstract/document/9650690/">
              <papertitle>Robust End-to-End Focal Liver Lesion Detection Using Unregistered Multiphase Computed
                Tomography Images
              </papertitle>
            </a>
            <br>
            <strong>Sang-gil Lee*</strong>,
            <a href="https://sites.google.com/snu.ac.kr/eunjikim">Eunji Kim*</a>,
            <a href="https://scholar.google.co.kr/citations?user=C_GxLiAAAAAJ">Jae Seok Bae*</a>,
            Jung Hoon Kim,
            <a href="https://scholar.google.com/citations?user=Bphl_fIAAAAJ">Sungroh Yoon</a>
            <br>
            <em>IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI)</em>, 2021
            <br>
            <a href="https://arxiv.org/abs/2112.01535">arXiv</a> /
            <a href="https://github.com/L0SG/grouped-ssd-pytorch">code</a>
            <p></p>
            <p>GSSD++ provides robustness to unregistered multi-phase CT images for detecting liver lesions using
              attention-guided multi-phase alignment with deformable convolutions. </p>
          </td>
        </tr>

        <tr onmouseout="gssd_stop()" onmouseover="gssd_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/gssd.png' width="160">
            </div>
            <script type="text/javascript">
                function gssd_start() {
                    document.getElementById('gssd_image').style.opacity = "1";
                }

                function gssd_stop() {
                    document.getElementById('gssd_image').style.opacity = "0";
                }

                gssd_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://link.springer.com/chapter/10.1007/978-3-030-00934-2_77">
              <papertitle>Liver Lesion Detection from Weakly-Labeled Multi-phase CT Volumes with a Grouped Single Shot
                MultiBox Detector
              </papertitle>
            </a>
            <br>
            <strong>Sang-gil Lee</strong>,
            <a href="https://scholar.google.co.kr/citations?user=C_GxLiAAAAAJ">Jae Seok Bae</a>,
            Hyunjae Kim,
            Jung Hoon Kim,
            <a href="https://scholar.google.com/citations?user=Bphl_fIAAAAJ">Sungroh Yoon</a>
            <br>
            <em>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)</em>,
            2018
            <br>
            <a href="https://arxiv.org/abs/1807.00436">arXiv</a> /
            <a href="https://github.com/L0SG/grouped-ssd-pytorch">code</a>
            <p></p>
            <p>GSSD pioneers a focal liver lesion detection model from multi-phase CT images, which reflects a
              real-world clinical practice of radiologists. </p>
          </td>
        </tr>

        </tbody>
      </table>

      <br>
      <br>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Experience</heading>
          </td>
        </tr>
        </tbody>
      </table>

      <table width="100%" align="center" border="0" cellpadding="20">
        <tbody>

        <tr>
          <td style="padding:10px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/nvidia.png' width="160">
            </div>
          </td>
          <td style="padding:10px;width:75%;vertical-align:top">

            <papertitle><span class="bigger">
                    Research Intern @ NVIDIA
                    </span></papertitle>
            <br>
            Sep 2021 - Jan 2022
            <br>
            <br>
            Worked on improving neural vocoders for high quality speech / audio synthesis, advised by
            <a href="https://wpingnet.github.io/">Wei Ping</a> and
            <a href="https://scholar.google.com/citations?user=7BRYaGcAAAAJ">Boris Ginsburg</a>.

          </td>
        </tr>

        <tr>
          <td style="padding:10px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/microsoft.jpeg' width="140">
            </div>
          </td>
          <td style="padding:10px;width:75%;vertical-align:top">

            <papertitle><span class="bigger">
                    Research Intern @ Microsoft Research Asia
                    </span></papertitle>
            <br>
            Dec 2020 - May 2021
            <br>
            Worked on diffusion-based generative models for speech synthesis, advised by
            <a href="https://tan-xu.github.io/">Xu Tan</a>,
            <a href="https://changliu00.github.io/">Chang Liu</a>,
            <a href="https://www.microsoft.com/en-us/research/people/meq/">Qi Meng</a>, and
            <a href="https://www.microsoft.com/en-us/research/people/taoqin/">Tao Qin</a>.
            <br>
            Dec 2018 - Feb 2019
            <br>
            Worked on <a href="https://www.microsoft.com/en-us/research/project/immunomics/">the Antigen Map Project</a>,
            where I applied sequence models to predict antigens from genetic sequences, advised by
            <a href="https://www.binshao.info/">Bin Shao</a>.

          </td>
        </tr>

        <tr>
          <td style="padding:10px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/kakao.png' width="140">
            </div>
          </td>
          <td style="padding:10px;width:75%;vertical-align:top">

            <papertitle><span class="bigger">
                    Research Intern @ Kakao Corporation
                    </span></papertitle>

            <br>
            Jul 2019 - Sep 2019
            <br>
            <br>
            Worked on improving speech synthesis and voice conversion models, advised by
            <a href="https://jaywalnut310.github.io/">Jaehyeon Kim</a> and <a
            href="https://scholar.google.com/citations?user=xUMMrvwAAAAJ">Jaekyong Bae</a>.

          </td>
        </tr>


        </tbody>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Education</heading>
          </td>
        </tr>
        </tbody>
      </table>

      <table width="100%" align="center" border="0" cellpadding="20">
        <tbody>

        <tr>
          <td style="padding:10px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/snu.png' width="140">
            </div>
          </td>
          <td style="padding:10px;width:75%;vertical-align:top">

            <papertitle><span class="bigger">
                    Ph.D. in Seoul National University
                    </span></papertitle>
            <br>
            <span class="bigger">
                    Electrical and Computer Engineering
                    </span>
            <br>
            Sep 2016 - Feb 2023 (expected)
            <li>Integrated M.S. / Ph.D. Program. &nbsp; Advisor: <a href="https://scholar.google.com/citations?user=Bphl_fIAAAAJ">Sungroh Yoon</a></li>
            <br>
            <papertitle><span class="bigger">
                    Dual B.S. in Seoul National University
                    </span></papertitle>
            <br>
            <span class="bigger">
                    Electrical and Computer Engineering / Applied Biology and Chemistry
                    </span>
            <br>
            Mar 2010 - Aug 2016
            <br>
            <li>Cum Laude</li>
          </td>
        </tr>

        </tbody>
      </table>

      <br>
      <br>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Invited Talks, Honors, and Awards</heading>
          </td>
        </tr>
        </tbody>
      </table>

      <table border=0 class="bg_colour"
             style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <ul>
          <li>Invited Talk "On Neural Waveform Synthesis", <a href="https://supertone.ai/">Supertone</a>, 2022</li>
          <li>Invited Talk "Prior Enhancement for Deep Generative Models", <a href="https://airsc.ai/">Hyundai AIRS</a>,
            2022
          </li>
          <li>Student Conference Scholarship, <a href="https://ai.google/">Google</a>, 2022</li>
          <li>Invited Talk "Neural Speech Synthesis: a 2021 Landscape", <a href="https://www.nvidia.com/">NVIDIA</a>,
            2021
          </li>
          <li>Gradate Student of the Year, DSAIL, Seoul National University, 2019</li>
          <li>Best Paper Award, <a href="https://airsc.ai/">Hyundai AIR Lab (currently AIRS)</a>, 2019</li>
          <li>Stars of Tomorrow (Excellent Intern), <a
            href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft Research Asia</a>,
            2019
          </li>
          <li>Invited Talk "RNN Plus Alpha: Is RNN the False Prophet?", <a href="https://clova.ai">Naver CLOVA</a>, 2018
          </li>
          <li>Cum Laude, Seoul National University, 2016</li>
          <li>Academic Performance Scholarship, Seoul National University, 2010 - 2016</li>
          <li>Academic Scholarship (fully funded), <a href="https://foundation.sbs.co.kr/">SBS Foundation</a>, 2010 -
            2016
          </li>
        </ul>
        </tbody>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Personal</heading>
          </td>
        </tr>
        </tbody>
      </table>

      <table width="100%" align="center" border="0" cellpadding="20">
        <tbody>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/L0SG_logo.jpg"
                                                                        width=140px></td>
          <td width="75%" valign="center">
            A PC hardware enthusiast. I like to learn anything about computers during my free time.
            <br>
            <br>
            A hobbyist DJ who enjoys house music. <a
            href="https://www.youtube.com/channel/UC2z2cvrNrA2wJsHcIAMwGdw">My mixes on YouTube</a>
          </td>
        </tr>
        </tbody>
      </table>

      <table
        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:right;font-size:small;">
              Last update: Aug 2022. Template borrowed from <a
              href="https://github.com/jonbarron/jonbarron_website">here</a>.
            </p>
          </td>
        </tr>
        </tbody>
      </table>
    </td>
  </tr>
</table>
</body>

</html>
